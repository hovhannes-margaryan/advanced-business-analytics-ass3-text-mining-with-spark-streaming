{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54586850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f9ea627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType, DoubleType\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "c = col\n",
    "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF, Word2Vec\n",
    "from sparkxgb import XGBoostClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import LinearSVC, LogisticRegression, GBTClassifier \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import classification_report, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584984c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutup \n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c31e7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8772fdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(header=True).csv(\"d.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b631d3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ea5f99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def lemmatize_text(tokens):\n",
    "#     doc = nlp(\" \".join(tokens))\n",
    "#     lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "#     return lemmatized_tokens\n",
    "\n",
    "\n",
    "# lemmatize_udf = udf(lemmatize_text, ArrayType(StringType()))\n",
    "\n",
    "regex = r'[!\\\"#$%&\\'()*+,\\-./:;<=>?@\\[\\\\\\]^_`{|}~]|(?<!\\w)(\"|/)(?!\\w)'\n",
    "\n",
    "df = (spark.read\n",
    "           .option(\"header\", \"true\")\n",
    "           .csv(\"./d.csv\").drop(\"_c0\")\n",
    "           .where(c(\"label\").isNotNull())\n",
    "           .where(c(\"review_text\").isNotNull())\n",
    "           .where(c(\"label\").isin([0, 1]))\n",
    "           .withColumn(\"review_text\", F.lower(c('review_text')))\n",
    "           .withColumn(\"review_text\", F.regexp_replace(c('review_text'), '\\d+', ''))\n",
    "           .withColumn(\"review_text\", F.regexp_replace(\"review_text\", regex, \"\"))\n",
    "           .where(c(\"review_text\") != '')\n",
    "     )\n",
    "\n",
    "train, test = df.select(\"review_text\", \"label\").randomSplit([0.8, 0.2], seed = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bb4436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         review_text|label|\n",
      "+--------------------+-----+\n",
      "|  not enough peko...|    1|\n",
      "| and at no point ...|    0|\n",
      "| and is a good ex...|    1|\n",
      "| and planetside h...|    1|\n",
      "| because right no...|    0|\n",
      "|                 btf|    0|\n",
      "| but i guess dim ...|    1|\n",
      "| but it still fee...|    1|\n",
      "| but its fun and ...|    1|\n",
      "| but out of luck ...|    0|\n",
      "| but theres enoug...|    1|\n",
      "| but wait until y...|    1|\n",
      "| buy this game it...|    1|\n",
      "| charming relaxin...|    1|\n",
      "| dollar game at b...|    0|\n",
      "| for temple run a...|    0|\n",
      "| hour and im alre...|    1|\n",
      "| hours in and it ...|    1|\n",
      "| hours in still h...|    1|\n",
      "| hours of my life...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "061405a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"review_text_tokens\", pattern=\"\\\\W\")\n",
    "add_tokens = tokenizer.transform(train)\n",
    "stop_word_remover = StopWordsRemover(inputCol=\"review_text_tokens\", outputCol=\"review_text_tokens_removed\")\n",
    "remove_stop_words = stop_word_remover.transform(add_tokens)\n",
    "\n",
    "# Tokenize the text\n",
    "# Apply TF-IDF\n",
    "cv = CountVectorizer(inputCol=\"review_text_tokens_removed\", outputCol=\"rawFeatures\")\n",
    "cvModel = cv.fit(remove_stop_words)\n",
    "featurizedData = cvModel.transform(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c09a3",
   "metadata": {},
   "source": [
    "### Number of docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8ccb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizedData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc22b70a",
   "metadata": {},
   "source": [
    "### Voncalubalry size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7faa57f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizedData.select(F.explode(c(\"review_text_tokens_removed\"))).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad7dbd",
   "metadata": {},
   "source": [
    "## top tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61edaa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|tokens|count|\n",
      "+------+-----+\n",
      "|   sht|  667|\n",
      "|   fck|  666|\n",
      "|  game|  624|\n",
      "|  like|  188|\n",
      "|   fun|  184|\n",
      "|  good|  151|\n",
      "| great|  100|\n",
      "|really|   91|\n",
      "| games|   82|\n",
      "|   get|   76|\n",
      "|   one|   75|\n",
      "|  play|   73|\n",
      "|  dont|   72|\n",
      "|  even|   68|\n",
      "|  time|   62|\n",
      "|   far|   61|\n",
      "| still|   58|\n",
      "| first|   58|\n",
      "|  love|   57|\n",
      "|  much|   56|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(featurizedData\n",
    ".select(F.explode(c(\"review_text_tokens_removed\")).alias(\"tokens\"))\n",
    ".groupBy(\"tokens\").count().orderBy(c(\"count\").desc())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c89d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = (featurizedData\n",
    "    .select(\"label\", F.explode(F.col(\"review_text_tokens_removed\")).alias(\"tokens\"))\n",
    "    .groupBy(\"tokens\", \"label\")\n",
    "    .count()\n",
    "    .orderBy(F.col(\"count\").desc())\n",
    ")\n",
    "\n",
    "window = Window.partitionBy(\"label\").orderBy(F.col(\"count\").desc())\n",
    "token_counts_with_rownumber = token_counts.withColumn(\"row_number\", F.row_number().over(window))\n",
    "\n",
    "top_tokens = token_counts_with_rownumber.filter(F.col(\"row_number\") <= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3f4b71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+\n",
      "|tokens|label|count|\n",
      "+------+-----+-----+\n",
      "|  game|    0|  187|\n",
      "|  like|    0|   55|\n",
      "|   get|    0|   31|\n",
      "|  dont|    0|   30|\n",
      "|  even|    0|   30|\n",
      "|   far|    0|   24|\n",
      "|  much|    0|   22|\n",
      "|  play|    0|   20|\n",
      "| games|    0|   19|\n",
      "|   one|    0|   19|\n",
      "|   sht|    1|  667|\n",
      "|   fck|    1|  666|\n",
      "|  game|    1|  437|\n",
      "|   fun|    1|  167|\n",
      "|  good|    1|  133|\n",
      "|  like|    1|  133|\n",
      "| great|    1|   92|\n",
      "|really|    1|   76|\n",
      "| games|    1|   63|\n",
      "|  love|    1|   57|\n",
      "+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_tokens.drop(\"row_number\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af144f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1969e4",
   "metadata": {},
   "source": [
    "### Full pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb8cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pipelineModel, test):\n",
    "    test_transformed = pipelineModel.transform(test)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = test_transformed.select(\"label\", \"prediction\")\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
    "                                                  predictionCol=\"prediction\",\n",
    "                                                  metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"Accuracy on test data:\", accuracy)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "454ea40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "           .option(\"header\", \"true\")\n",
    "           .csv(\"./d.csv\").drop(\"_c0\")\n",
    "           .where(c(\"label\").isNotNull())\n",
    "           .where(c(\"review_text\").isNotNull())\n",
    "           .where(c(\"label\").isin([0, 1]))\n",
    "           .withColumn(\"review_text\", F.lower(c('review_text')))\n",
    "           .withColumn(\"review_text\", F.regexp_replace(c('review_text'), '\\d+', ''))\n",
    "           .withColumn(\"review_text\", F.regexp_replace(\"review_text\", regex, \"\"))\n",
    "           .where(c(\"review_text\") != '')\n",
    "     ).withColumn(\"label\", c(\"label\").cast(DoubleType()))\n",
    "\n",
    "train, test = df.select(\"review_text\", \"label\").randomSplit([0.8, 0.2], seed = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1f3deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline stages\n",
    "tokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"review_text_tokens\", pattern=\"\\\\W\")\n",
    "stop_word_remover = StopWordsRemover(inputCol=\"review_text_tokens\", outputCol=\"review_text_tokens_removed\")\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"review_text_tokens_removed\", outputCol=\"word2VecFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73dc82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_logistic = LogisticRegression(featuresCol=\"word2VecFeatures\", labelCol=\"label\")\n",
    "classifier_boosting = GBTClassifier(featuresCol=\"word2VecFeatures\", labelCol=\"label\")\n",
    "classifier_svc = LinearSVC(featuresCol=\"word2VecFeatures\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8af9d3",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efc4349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipeline_logistic = Pipeline(stages=[tokenizer, stop_word_remover, word2Vec, classifier_logistic])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipelineModel_logistic = pipeline_logistic.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5753c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.7848101265822784\n"
     ]
    }
   ],
   "source": [
    "predict_logistic = predict(pipelineModel_logistic, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20496d31",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65fc5c",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f6a260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_boosting = Pipeline(stages=[tokenizer, stop_word_remover, word2Vec, classifier_boosting])\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(classifier_boosting.maxDepth, [5, 10])\n",
    "             .addGrid(classifier_boosting.maxBins,  [20, 30])\n",
    "             .build())\n",
    "\n",
    "# Set up the cross-validator\n",
    "crossval = CrossValidator(estimator=pipeline_boosting,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)\n",
    "\n",
    "crossvalModel = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3af75dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.759493670886076\n"
     ]
    }
   ],
   "source": [
    "predict_boost = predict(crossvalModel, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3de19b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d3e6e",
   "metadata": {},
   "source": [
    "### Support vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48aeed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svc = Pipeline(stages=[tokenizer, stop_word_remover, word2Vec, classifier_svc])\n",
    "\n",
    "# Define the parameter grid\n",
    "paramGrid_svc = (ParamGridBuilder()\n",
    "                 .addGrid(classifier_svc.maxIter, [100, 200])\n",
    "                 .addGrid(classifier_svc.regParam, [0.0001,0.01,0.1, 0.2])\n",
    "                 .build())\n",
    "\n",
    "\n",
    "# Set up the cross-validator\n",
    "crossval_svc = CrossValidator(estimator=pipeline_svc,\n",
    "                              estimatorParamMaps=paramGrid_svc,\n",
    "                              evaluator=BinaryClassificationEvaluator(),\n",
    "                              numFolds=3)\n",
    "\n",
    "crossvalModel_svc = crossval_svc.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f782063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.7932489451476793\n"
     ]
    }
   ],
   "source": [
    "predict_svc = predict(crossvalModel_svc, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8dc6a2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe56c11",
   "metadata": {},
   "source": [
    "### Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53457fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        49\n",
      "         1.0       0.79      1.00      0.88       188\n",
      "\n",
      "    accuracy                           0.79       237\n",
      "   macro avg       0.40      0.50      0.44       237\n",
      "weighted avg       0.63      0.79      0.70       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lab_true_svc = predict_svc.select('label').toPandas()['label'].values\n",
    "lab_pred_svc = predict_svc.select('prediction').toPandas()['prediction'].values\n",
    "print(classification_report(lab_true_svc, lab_pred_svc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
